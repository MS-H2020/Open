{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MS-H2020/Open/blob/main/Car_Object_Detection_Mask_RCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JRbDY44pOzv"
      },
      "source": [
        "# [Car Object Detection](https://www.kaggle.com/datasets/sshikamaru/car-object-detection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n76CTiRopYzy"
      },
      "source": [
        "## Reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4eFRzjqpcBh"
      },
      "source": [
        "1 [ASHISHSINGH226, \"Car-Detection-Using-MaskRCNN\"](https://www.kaggle.com/code/ashishsingh226/car-detection-using-maskrcnn)  \n",
        "2 [Jason Brownlee, \"How to Train an Object Detection Model with Keras\", Machine Learning Maestry, Sep.2020](https://machinelearningmastery.com/how-to-train-an-object-detection-model-with-keras/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd9Jil0fo_AA"
      },
      "source": [
        "## 0. Setting for Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1GSeGbboG9L",
        "outputId": "7a9317b1-a73c-44a9-8f24-d20ccafcb3df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tM6uWW0sovJZ"
      },
      "outputs": [],
      "source": [
        "INPUT_DIR:str = \"/content/drive/MyDrive/Car_Object_Detection/01_input\"\n",
        "TRAIN_DIR:str = \"./training_images\"\n",
        "TEST_DIR:str = \"./testing_images\"\n",
        "ANALYSIS_DIR:str = \"/content/drive/MyDrive/Car_Object_Detection/03_code-analysis\"\n",
        "MODEL_DIR:str = \"/content/drive/MyDrive/Car_Object_Detection//04_model\"\n",
        "SUBMISSION_DIR:str = '/content/drive/MyDrive/Car_Object_Detection/05_submission'\n",
        "CHECKPOINT_PATH:str = MODEL_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c8AgE_Qo07u"
      },
      "outputs": [],
      "source": [
        "import os, gc, glob, shutil, zipfile\n",
        "shutil.unpack_archive(INPUT_DIR+'/training_images.zip', './')\n",
        "shutil.unpack_archive(INPUT_DIR+'/testing_images.zip', './')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_EpqzJ-qyJt"
      },
      "source": [
        "## 1. Importing and Installing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myRFJgxMq1Iw",
        "outputId": "c0a13611-421d-4557-d43f-519af3e3d18d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mask-RCNN-TF2-10'...\n",
            "remote: Enumerating objects: 1459, done.\u001b[K\n",
            "remote: Total 1459 (delta 0), reused 0 (delta 0), pack-reused 1459\u001b[K\n",
            "Receiving objects: 100% (1459/1459), 157.06 MiB | 28.25 MiB/s, done.\n",
            "Resolving deltas: 100% (798/798), done.\n",
            "WARNING:root:Fail load requirements file, so using default ones.\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/dist.py:755: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Usage of dash-separated 'description-file' will not be supported in future\n",
            "        versions. Please use the underscore name 'description_file' instead.\n",
            "\n",
            "        This deprecation is overdue, please update your project and remove deprecated\n",
            "        calls to avoid build errors in the future.\n",
            "\n",
            "        See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  opt = self.warn_dash_deprecation(opt, section)\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/dist.py:755: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Usage of dash-separated 'license-file' will not be supported in future\n",
            "        versions. Please use the underscore name 'license_file' instead.\n",
            "\n",
            "        This deprecation is overdue, please update your project and remove deprecated\n",
            "        calls to avoid build errors in the future.\n",
            "\n",
            "        See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  opt = self.warn_dash_deprecation(opt, section)\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/dist.py:755: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Usage of dash-separated 'requirements-file' will not be supported in future\n",
            "        versions. Please use the underscore name 'requirements_file' instead.\n",
            "\n",
            "        This deprecation is overdue, please update your project and remove deprecated\n",
            "        calls to avoid build errors in the future.\n",
            "\n",
            "        See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  opt = self.warn_dash_deprecation(opt, section)\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/config/setupcfg.py:293: _DeprecatedConfig: Deprecated config in `setup.cfg`\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        The license_file parameter is deprecated, use license_files instead.\n",
            "\n",
            "        This deprecation is overdue, please update your project and remove deprecated\n",
            "        calls to avoid build errors in the future.\n",
            "\n",
            "        See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  parsed = self.parsers.get(option_name, lambda x: x)(value)\n",
            "INFO:root:running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "INFO:root:running bdist_egg\n",
            "INFO:root:running egg_info\n",
            "INFO:root:creating mask_rcnn_tf2.egg-info\n",
            "INFO:root:writing mask_rcnn_tf2.egg-info/PKG-INFO\n",
            "INFO:root:writing dependency_links to mask_rcnn_tf2.egg-info/dependency_links.txt\n",
            "INFO:root:writing top-level names to mask_rcnn_tf2.egg-info/top_level.txt\n",
            "INFO:root:writing manifest file 'mask_rcnn_tf2.egg-info/SOURCES.txt'\n",
            "INFO:root:reading manifest file 'mask_rcnn_tf2.egg-info/SOURCES.txt'\n",
            "INFO:root:reading manifest template 'MANIFEST.in'\n",
            "INFO:root:adding license file 'LICENSE'\n",
            "INFO:root:writing manifest file 'mask_rcnn_tf2.egg-info/SOURCES.txt'\n",
            "INFO:root:installing library code to build/bdist.linux-x86_64/egg\n",
            "INFO:root:running install_lib\n",
            "INFO:root:running build_py\n",
            "INFO:root:creating build\n",
            "INFO:root:creating build/lib\n",
            "INFO:root:creating build/lib/mrcnn\n",
            "INFO:root:copying mrcnn/utils.py -> build/lib/mrcnn\n",
            "INFO:root:copying mrcnn/config.py -> build/lib/mrcnn\n",
            "INFO:root:copying mrcnn/parallel_model.py -> build/lib/mrcnn\n",
            "INFO:root:copying mrcnn/visualize.py -> build/lib/mrcnn\n",
            "INFO:root:copying mrcnn/__init__.py -> build/lib/mrcnn\n",
            "INFO:root:copying mrcnn/model.py -> build/lib/mrcnn\n",
            "INFO:root:copying mrcnn/model_temp.py -> build/lib/mrcnn\n",
            "INFO:root:creating build/bdist.linux-x86_64\n",
            "INFO:root:creating build/bdist.linux-x86_64/egg\n",
            "INFO:root:creating build/bdist.linux-x86_64/egg/mrcnn\n",
            "INFO:root:copying build/lib/mrcnn/utils.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "INFO:root:copying build/lib/mrcnn/config.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "INFO:root:copying build/lib/mrcnn/parallel_model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "INFO:root:copying build/lib/mrcnn/visualize.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "INFO:root:copying build/lib/mrcnn/__init__.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "INFO:root:copying build/lib/mrcnn/model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "INFO:root:copying build/lib/mrcnn/model_temp.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "INFO:root:byte-compiling build/bdist.linux-x86_64/egg/mrcnn/utils.py to utils.cpython-310.pyc\n",
            "INFO:root:byte-compiling build/bdist.linux-x86_64/egg/mrcnn/config.py to config.cpython-310.pyc\n",
            "INFO:root:byte-compiling build/bdist.linux-x86_64/egg/mrcnn/parallel_model.py to parallel_model.cpython-310.pyc\n",
            "INFO:root:byte-compiling build/bdist.linux-x86_64/egg/mrcnn/visualize.py to visualize.cpython-310.pyc\n",
            "INFO:root:byte-compiling build/bdist.linux-x86_64/egg/mrcnn/__init__.py to __init__.cpython-310.pyc\n",
            "INFO:root:byte-compiling build/bdist.linux-x86_64/egg/mrcnn/model.py to model.cpython-310.pyc\n",
            "INFO:root:byte-compiling build/bdist.linux-x86_64/egg/mrcnn/model_temp.py to model_temp.cpython-310.pyc\n",
            "build/bdist.linux-x86_64/egg/mrcnn/model_temp.py:2360: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if os.name is 'nt':\n",
            "INFO:root:creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "INFO:root:copying mask_rcnn_tf2.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "INFO:root:copying mask_rcnn_tf2.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "INFO:root:copying mask_rcnn_tf2.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "INFO:root:copying mask_rcnn_tf2.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "WARNING:root:zip_safe flag not set; analyzing archive contents...\n",
            "INFO:root:creating dist\n",
            "INFO:root:creating 'dist/mask_rcnn_tf2-1.0-py3.10.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "INFO:root:removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "INFO:root:Processing mask_rcnn_tf2-1.0-py3.10.egg\n",
            "INFO:root:Copying mask_rcnn_tf2-1.0-py3.10.egg to /usr/local/lib/python3.10/dist-packages\n",
            "INFO:root:Adding mask-rcnn-tf2 1.0 to easy-install.pth file\n",
            "INFO:root:\n",
            "Installed /usr/local/lib/python3.10/dist-packages/mask_rcnn_tf2-1.0-py3.10.egg\n",
            "INFO:root:Processing dependencies for mask-rcnn-tf2==1.0\n",
            "INFO:root:Finished processing dependencies for mask-rcnn-tf2==1.0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ahmedfgad/Mask-RCNN-TF2.git\n",
        "!cd Mask-RCNN-TF2 && python setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorflow\n",
        "! pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB6H6Zt5akqf",
        "outputId": "fb818736-75c7-479d-8aba-9b304006ea09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS1t50DWraFB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "outputId": "f54258b8-ca35-4b24-e82a-d42e23595b70"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras.engine'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-302f1080817b>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay_instances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMaskRCNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_ap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_image_gt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Mask-RCNN-TF2-10/mrcnn/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mKL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mKE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mKM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.engine'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os,sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from numpy import zeros, asarray, expand_dims, mean\n",
        "from matplotlib import pyplot\n",
        "\n",
        "ROOT_DIR = os.path.abspath(\"./Mask-RCNN-TF2-10\")\n",
        "sys.path.append(ROOT_DIR)\n",
        "\n",
        "from mrcnn.utils import Dataset,extract_bboxes\n",
        "from mrcnn.visualize import display_instances\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.model import MaskRCNN\n",
        "from mrcnn.utils import compute_ap\n",
        "from mrcnn.model import load_image_gt\n",
        "from mrcnn.model import mold_image\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hk0RyamqzehU"
      },
      "outputs": [],
      "source": [
        "bb_df = pd.read_csv(INPUT_DIR+'/train_solution_bounding_boxes.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ecXl_qWz1VK"
      },
      "outputs": [],
      "source": [
        "bb_df.head() #displaying the first couple of rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkKPF8Mvz_oR"
      },
      "outputs": [],
      "source": [
        "bb_df.nunique() #count of unique values in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-wV8AOA0I72"
      },
      "outputs": [],
      "source": [
        "class CarsDataset(Dataset):\n",
        "    '''\n",
        "    Dataset class to load the images and their bounding boxes in the form of masks\n",
        "    '''\n",
        "    def load_dataset(self, dataset_dir='./', mode='train'):\n",
        "        '''\n",
        "        This function is used to load the dataset. We will only use 500 images for training the rest are for validation.\n",
        "        We also have test set for which we dont have labels but are useful for visually checking\n",
        "        for how effective the training was\n",
        "        '''\n",
        "        self.add_class('dataset',1,'car')\n",
        "        if mode=='train':\n",
        "            images_dir = dataset_dir + 'training_images/'\n",
        "            for i in range(500):\n",
        "                image_id = bb_df.iloc[i,0]\n",
        "                img_path = images_dir + image_id\n",
        "                self.add_image('dataset', image_id=image_id, path=img_path)\n",
        "        if mode=='val':\n",
        "            images_dir = dataset_dir + 'training_images/'\n",
        "            for i in range(500,len(bb_df)):\n",
        "                image_id = bb_df.iloc[i,0]\n",
        "                img_path = images_dir + image_id\n",
        "                self.add_image('dataset', image_id=image_id, path=img_path)\n",
        "        if mode=='test':\n",
        "            images_dir = dataset_dir + 'testing_images/'\n",
        "            for filename in listdir(images_dir):\n",
        "                image_id = filename\n",
        "                img_path = images_dir + filename\n",
        "                self.add_image('dataset', image_id=image_id, path=img_path)\n",
        "\n",
        "    def extract_boxes(self, filename):\n",
        "        '''\n",
        "        To get the coordinates of the bounding boxes.\n",
        "        '''\n",
        "        boxes = list()\n",
        "        xmin = int(bb_df[bb_df['image']==filename].iloc[0,1])\n",
        "        ymin = int(bb_df[bb_df['image']==filename].iloc[0,2])\n",
        "        xmax = int(bb_df[bb_df['image']==filename].iloc[0,3])\n",
        "        ymax = int(bb_df[bb_df['image']==filename].iloc[0,4])\n",
        "        coors = [xmin, ymin, xmax, ymax]\n",
        "        boxes.append(coors)\n",
        "        width = 380\n",
        "        height = 676\n",
        "        return boxes, width, height\n",
        "    def load_mask(self, image_id):\n",
        "        '''\n",
        "        Takes the co-ordinates and uses that to make it into a mask.\n",
        "        '''\n",
        "        info = self.image_info[image_id]\n",
        "        file = info['id']\n",
        "        boxes, w, h = self.extract_boxes(file)\n",
        "        masks = zeros([w, h, len(boxes)], dtype='uint8')\n",
        "        class_ids = list()\n",
        "        for i in range(len(boxes)):\n",
        "            box = boxes[i]\n",
        "            row_s, row_e = box[1], box[3]\n",
        "            col_s, col_e = box[0], box[2]\n",
        "            masks[row_s:row_e, col_s:col_e, i] = 1\n",
        "            class_ids.append(self.class_names.index('car'))\n",
        "        return masks, asarray(class_ids, dtype='int32')\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        return info['path']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXE_kW6P1SBf"
      },
      "outputs": [],
      "source": [
        "#Loading all the datasets we will need.\n",
        "train_set = CarsDataset()\n",
        "train_set.load_dataset(mode='train')\n",
        "train_set.prepare()\n",
        "print('Train: %d' % len(train_set.image_ids))\n",
        "\n",
        "val_set = CarsDataset()\n",
        "val_set.load_dataset(mode='val')\n",
        "val_set.prepare()\n",
        "print('Validate: %d' % len(val_set.image_ids))\n",
        "\n",
        "test_set = CarsDataset()\n",
        "test_set.load_dataset(mode='test')\n",
        "test_set.prepare()\n",
        "print('Test: %d' % len(test_set.image_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YI43CQ5U1Wbv"
      },
      "outputs": [],
      "source": [
        "def plot(num_img=5):\n",
        "    for i in range(num_img):\n",
        "        image_id = np.random.randint(0,len(train_set.image_ids))\n",
        "        image = train_set.load_image(image_id)\n",
        "        mask, class_ids = train_set.load_mask(image_id)\n",
        "        pyplot.imshow(image)\n",
        "        pyplot.imshow(mask[:, :, 0], cmap='gray', alpha=0.3)\n",
        "        pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fg2Kheuh1Xcl"
      },
      "outputs": [],
      "source": [
        "plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oIKPXrJ1dli"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xALkgN6s1hno"
      },
      "source": [
        "This config file contains a lot of important parameters for model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpd8g4H71nDD"
      },
      "outputs": [],
      "source": [
        "class CarsConfig(Config):\n",
        "    NAME = \"cars_cfg\"\n",
        "    NUM_CLASSES = 2 #Bckground is counted as class too so background + cars = 2 labels\n",
        "    STEPS_PER_EPOCH = 200\n",
        "    VALIDATION_STEPS = 20\n",
        "    IMAGES_PER_GPU = 1\n",
        "    IMAGE_MIN_DIM = 384\n",
        "    IMAGE_MAX_DIM = 448\n",
        "\n",
        "config = CarsConfig()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJeaeV431tFv"
      },
      "outputs": [],
      "source": [
        "config.display() #list of all available configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXAqK4q51xrQ"
      },
      "outputs": [],
      "source": [
        "model = MaskRCNN(mode='training', model_dir='./', config=config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQWnfUCo16Hp"
      },
      "source": [
        "We are going to load pre-trained weights for this task. This will save us a lot of time because these algorithms can take a lot of time to converge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kD1j99r9mHAV"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bgxXoHN18Z8"
      },
      "outputs": [],
      "source": [
        "model.load_weights('./mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wip-nRCU2Gly"
      },
      "outputs": [],
      "source": [
        "model.train(train_set, val_set, learning_rate=config.LEARNING_RATE, epochs=10, layers='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD0lzrgd2KQr"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6mba0p82Okr"
      },
      "source": [
        "We need to define a seperate config file for predictions purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlxEq5vw2Smh"
      },
      "outputs": [],
      "source": [
        "class PredictionConfig(Config):\n",
        "    NAME = \"cars_cfg\"\n",
        "    NUM_CLASSES = 2\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    USE_MINI_MASK = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9lIH28J2ZA_"
      },
      "outputs": [],
      "source": [
        "cfg = PredictionConfig()\n",
        "model = MaskRCNN(mode='inference', model_dir='./' config=cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfT4EnNg2ilv"
      },
      "source": [
        "Loading the saved weights to perform inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbV_F-no2jiv"
      },
      "outputs": [],
      "source": [
        "for i in listdir():\n",
        "    if i[:4]=='cars':\n",
        "        path=i\n",
        "model.load_weights('./'+path+'/mask_rcnn_cars_cfg_0010.h5', by_name=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_rZJYDz2sdn"
      },
      "source": [
        "Here we will calculate mean average precision for our model. To know in detail what it means try referring to this blog https://towardsdatascience.com/map-mean-average-precision-might-confuse-you-5956f1bfa9e2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOr3cCiQ3KUV"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(dataset, model, cfg):\n",
        "    APs = list()\n",
        "    for image_id in dataset.image_ids:\n",
        "        image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id)\n",
        "        scaled_image = mold_image(image, cfg)\n",
        "        sample = expand_dims(scaled_image, 0)\n",
        "        yhat = model.detect(sample, verbose=0)\n",
        "        r = yhat[0]\n",
        "        AP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "        APs.append(AP)\n",
        "    mAP = mean(APs)\n",
        "    return mAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCEn1snJ3OAP"
      },
      "outputs": [],
      "source": [
        "train_mAP = evaluate_model(train_set, model, cfg)\n",
        "print(\"Train mAP: %.3f\" % train_mAP)\n",
        "val_mAP = evaluate_model(val_set, model, cfg)\n",
        "print(\"Validation mAP: %.3f\" % val_mAP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUtvshhG3Tb6"
      },
      "source": [
        "## Actual vs Predicted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DNCzF-d3Uwg"
      },
      "source": [
        "Fianlly we will compare our model preformances by simply seeing how well it is detecting cars compared to the real bounding boxes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJ3wvhEx3X6X"
      },
      "outputs": [],
      "source": [
        "def plot_actual_vs_predicted(dataset, model, cfg, n_images=5):\n",
        "    for i in range(n_images):\n",
        "        id = np.random.randint(0,len(dataset.image_ids))\n",
        "        pyplot.figure(figsize=(50, 50))\n",
        "        image = dataset.load_image(id)\n",
        "        mask, _ = dataset.load_mask(id)\n",
        "        scaled_image = mold_image(image, cfg)\n",
        "        sample = expand_dims(scaled_image, 0)\n",
        "        yhat = model.detect(sample, verbose=0)[0]\n",
        "        pyplot.subplot(n_images, 2, i*2+1)\n",
        "        pyplot.imshow(image)\n",
        "        pyplot.title('Actual')\n",
        "        for j in range(mask.shape[2]):\n",
        "            pyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
        "        pyplot.subplot(n_images, 2, i*2+2)\n",
        "        pyplot.imshow(image)\n",
        "        pyplot.title('Predicted')\n",
        "        ax = pyplot.gca()\n",
        "        for box in yhat['rois']:\n",
        "            y1, x1, y2, x2 = box\n",
        "            width, height = x2 - x1, y2 - y1\n",
        "            rect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
        "            ax.add_patch(rect)\n",
        "    pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIIf3x9W3dnN"
      },
      "outputs": [],
      "source": [
        "from matplotlib.patches import Rectangle\n",
        "plot_actual_vs_predicted(val_set, model, cfg)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}