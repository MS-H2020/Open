{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1qIfzi3tVlBsG-B972mNlA50FsHNjk2W6",
      "authorship_tag": "ABX9TyMUWzlG5F7OU2A2BOXy4tJn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MS-H2020/Open/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [プリント基板の電子部品検出 Nishika株式会社](https://competition.nishika.com/competitions/kiban/summary)"
      ],
      "metadata": {
        "id": "PZrVyk648wcx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Environment"
      ],
      "metadata": {
        "id": "zpfATCNz_KJl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/drive/MyDrive/PCB_Detect/: Working directory  \n",
        "┣ 01_input: A directory includes input data in competition  \n",
        "┃ ┣ train_imgs.zip: A zip file including train images    \n",
        "┃ ┣ test_imgs.zip: A zip file including test images  \n",
        "┃ ┣ train.csv:  A csv file in which table data written for training.   \n",
        "┃ ┣ test.csv: A csv file in which table data written for test.  \n",
        "┃ ┗ sample_submission.csv: A csv file is sample for submission.  \n",
        "┣ 03_code: A directory for main code.\n",
        "┣ 04_model: A directory for model.  \n",
        "┗ 05_submission: A directory for submission data file.  "
      ],
      "metadata": {
        "id": "JPU-3cQV_SgO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xeqhS-K18syh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "798f94b6-5e77-449a-c595-5de5f7f080f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEMP_DIR = \"./temp\"\n",
        "INPUT_DIR:str = \"/content/drive/MyDrive/PCB_Detect/01_input\"\n",
        "#TRAIN_DIR:str = INPUT_DIR + \"/train_data\"\n",
        "#TEST_DIR:str = INPUT_DIR + \"/test_data\"\n",
        "#ANALYSIS_DIR:str = \"/content/drive/MyDrive/Human_Activity_Recognition_with_Smartphones/03_code-analysis\"\n",
        "MODEL_DIR:str = \"/content/drive/MyDrive/PCB_Detect//04_model\"\n",
        "SUBMISSION_DIR:str = '/content/drive/MyDrive/PCB_Detect/05_submission'\n",
        "CHECKPOINT_PATH:str = MODEL_DIR"
      ],
      "metadata": {
        "id": "hEDjOdKv_-It"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, glob, zipfile\n",
        "\n",
        "if not os.path.isdir('./train_imgs') and  not os.path.isdir('./test_imgs'):\n",
        "  # Copy ZIP files including images, and Unzip them.\n",
        "  !cp -r \"/content/drive/MyDrive/PCB_Detect/01_input/train_imgs.zip\" ./\n",
        "  !cp -r \"/content/drive/MyDrive/PCB_Detect/01_input/test_imgs.zip\" ./\n",
        "  shutil.unpack_archive('train_imgs.zip', './')\n",
        "  shutil.unpack_archive('test_imgs.zip', './')"
      ],
      "metadata": {
        "id": "84YuoQOhArRx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Rle decoding with tensorflow"
      ],
      "metadata": {
        "id": "2F5ixMfqDNuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def rle_decode_tf(mask_rle, shape):\n",
        "    shape = tf.convert_to_tensor(shape, tf.int64)\n",
        "    size = tf.math.reduce_prod(shape)\n",
        "    # Split string\n",
        "    s = tf.strings.split(mask_rle)\n",
        "    s = tf.strings.to_number(s, tf.int64)\n",
        "    # Get starts and lengths\n",
        "    starts = s[::2] - 1\n",
        "    lens = s[1::2]\n",
        "    # Make ones to be scattered\n",
        "    total_ones = tf.reduce_sum(lens)\n",
        "    ones = tf.ones([total_ones], tf.uint8)\n",
        "    # Make scattering indices\n",
        "    r = tf.range(total_ones)\n",
        "    lens_cum = tf.math.cumsum(lens)\n",
        "    s = tf.searchsorted(lens_cum, r, 'right')\n",
        "    idx = r + tf.gather(starts - tf.pad(lens_cum[:-1], [(1, 0)]), s)\n",
        "    # Scatter ones into flattened mask\n",
        "    mask_flat = tf.scatter_nd(tf.expand_dims(idx, 1), ones, [size])\n",
        "    # Reshape into mask\n",
        "    return tf.reshape(mask_flat, shape)"
      ],
      "metadata": {
        "id": "kqaZwOKWDYph"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}